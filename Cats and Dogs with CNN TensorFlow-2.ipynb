{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Cats and Dogs with CNN TensorFlow"},{"metadata":{"trusted":true,"_uuid":"6a3ba2ba0518bdaa56565e72ba6230a1866f9b6d"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport random\nimport pickle\nimport time\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe24c249c2ef54344e16e53e545b213a56205f8a"},"cell_type":"markdown","source":"## Data"},{"metadata":{"trusted":true,"_uuid":"6579fc4e9d3018e0dc566d4ca99d64e9979576be"},"cell_type":"code","source":"DATADIR = '../input/kagglecatsanddogs_3367a/PetImages'\nCATEGORIES = ['Dog','Cat']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46fe9c367d1bd6c236b881ec0bc28c927482e25f"},"cell_type":"markdown","source":"## Preprocess Dataset"},{"metadata":{"trusted":true,"_uuid":"4111a522606d86c060551097c882dd87c1621d7e"},"cell_type":"code","source":"#Iterate and convert datasets to an array.\n\nfor category in CATEGORIES:\n    path = os.path.join(DATADIR, category) # path to dataset directory\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n        plt.imshow(img_array, cmap='gray')\n        plt.show()\n        break\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96a0f9d8151197fed5ebd44ba7d4c3de51383776"},"cell_type":"code","source":"# Checking Data\nprint('Data Array:\\n',img_array,'\\n')\nprint('Data Shape:',img_array.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9e25b7fff4c947fd58193f1e19c8d67f120194a"},"cell_type":"code","source":"# Resize the image\nIMG_SIZE = 80\nnew_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\nplt.imshow(new_array, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b1f936da080e8d26768a0bda984eefc2a22e959"},"cell_type":"code","source":"# Create dataset for training\n\ntraining_data = []\n\ndef create_training_data():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category) # categories for dog(0) and cat(1)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n                training_data.append([new_array,class_num])\n            except Exception as e:\n                pass\n        \ncreate_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9559a14e30c64e0f431244da22ffb0b80b650565"},"cell_type":"code","source":"print(len(training_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6418299e82525fd8924b156fff514d996449ed57"},"cell_type":"code","source":"# Reshuffle Data\nrandom.shuffle(training_data)\n\n# Check the shuffled data\nfor sample in training_data [:10]:\n    print(sample[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb144f2651ce92a2b8cadea5ea0e83cc745394fa"},"cell_type":"code","source":"# Create list for training data\nX = [] # feature dataset\ny = [] # label dataset\n\nfor features, label in training_data:\n    X.append(features)\n    y.append(label)\n\n# Convert X to an array since you can't pass it to a neural network\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\nprint(X[:1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae1270c038d222c697c9cbf4b1f151954a9d35d4"},"cell_type":"code","source":"# Save traing set using pickle\n\npickle_out = open('X.pickle', 'wb')\npickle.dump(X, pickle_out)\npickle_out.close()\n\npickle_out = open('y.pickle', 'wb')\npickle.dump(y, pickle_out)\npickle_out.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2e058c6fbf6efd292f9b31088c7b1a185a343fd"},"cell_type":"code","source":"# Open pickle file\n\npickle_in = open('X.pickle','rb')\nX = pickle.load(pickle_in)\nX[1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd74483303e78330a6da9dd1cec00d207efc98ac"},"cell_type":"markdown","source":"## The Model"},{"metadata":{"trusted":true,"_uuid":"cedba2458d0d82e4612106ffc2caaffb78fd9b58"},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import TensorBoard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"853563d8a95604a8da00eb2b1f6459cdf9de525c"},"cell_type":"code","source":"# Callback Name for Tensorboard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f38a42e65d322ac0a08917be12f733a2e3debe3"},"cell_type":"code","source":"# Optimizing GPU\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aba67fa1a518138ac77fad10ea2a7b9cdddf241c"},"cell_type":"code","source":"# Load saved datasets\n\npickle_in = open('X.pickle','rb')\nX = pickle.load(pickle_in)\n\npickle_in = open('y.pickle','rb')\ny = pickle.load(pickle_in)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7187d8af074190af9fcb76a118d37a5f3f4b3df2"},"cell_type":"code","source":"# Normalized Datasets\nX = X/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fde48186988fcb936783bf45f189d7218f960bb"},"cell_type":"code","source":"# Build Model\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, (3,3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten()) #to convert 3D feature map to 1D\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd85b39824f5f0c310a1ece2fc81312d5785e4f1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}